{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of event per day\n",
      "current day: 2017-10-01\n",
      "Start collect\n",
      "collected 10 tweets\n",
      "current day: 2017-10-02\n",
      "Start collect\n",
      "collected 10 tweets\n",
      "current day: 2017-10-03\n",
      "Start collect\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-03%20until%3A2017-10-04%20Worlds2017&src=typd\n",
      "error while collecting tweets of day 2017-10-03\n",
      "current day: 2017-10-03\n",
      "Start collect\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-03%20until%3A2017-10-04%20Worlds2017&src=typd\n",
      "error while collecting tweets of day 2017-10-03\n",
      "current day: 2017-10-03\n",
      "Start collect\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-03%20until%3A2017-10-04%20Worlds2017&src=typd\n",
      "error while collecting tweets of day 2017-10-03\n",
      "current day: 2017-10-03\n",
      "Start collect\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import http.cookiejar\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyquery import PyQuery\n",
    "\n",
    "\n",
    "class Tweet:\n",
    "    \"\"\"\n",
    "    Holds tweet information.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class QueryArgs:\n",
    "    \"\"\"\n",
    "    Twitter advanced search arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, results=1, query=None, username=None, location=None, location_radius=None, since=None,\n",
    "                 until=None, lang=None, top_tweets=None):\n",
    "        self.results = results\n",
    "        self.query = query\n",
    "        self.username = username\n",
    "        self.location = location\n",
    "        self.location_radius = location_radius\n",
    "        self.since = since\n",
    "        self.until = until\n",
    "        self.lang = lang\n",
    "        self.top_tweets = top_tweets\n",
    "\n",
    "\n",
    "class TweetAdvancedQuery:\n",
    "    \"\"\"\n",
    "    Runs the search using http and json to recover the tweet information.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def query(args, proxy=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the query with the received args and returns the collected tweets.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print('Start collect')\n",
    "\n",
    "        refresh_cursor = ''\n",
    "        results = []\n",
    "        cookie_jar = http.cookiejar.CookieJar()\n",
    "        active = True\n",
    "\n",
    "        while active:\n",
    "            json = TweetAdvancedQuery._get_json_reponse(args, refresh_cursor, cookie_jar, proxy)\n",
    "            if len(json['items_html'].strip()) == 0:\n",
    "                break\n",
    "\n",
    "            refresh_cursor = json['min_position']            \n",
    "            tweets = PyQuery(json['items_html'])('div.js-stream-tweet')\n",
    "            if len(tweets) == 0:\n",
    "                break\n",
    "\n",
    "            for tweet_html in tweets:\n",
    "                tweet_pq = PyQuery(tweet_html)\n",
    "                tweet = Tweet()\n",
    "                tweet_username = tweet_pq('span.username.js-action-profile-name b').text()\n",
    "                tweet_text = re.sub(r'\\s+', ' ', tweet_pq('p.js-tweet-text').text().replace('# ', '#').replace('@ ', '@'))\n",
    "                retweets = int(tweet_pq('span.ProfileTweet-action--retweet span.ProfileTweet-actionCount').attr('data-tweet-stat-count').replace(',', ''))\n",
    "                favorites = int(tweet_pq('span.ProfileTweet-action--favorite span.ProfileTweet-actionCount').attr('data-tweet-stat-count').replace(',', ''))\n",
    "                date_info = int(tweet_pq('small.time span.js-short-timestamp').attr('data-time'))\n",
    "                tweet_id = tweet_pq.attr('data-tweet-tweet_id')\n",
    "                permalink = tweet_pq.attr('data-permalink-path')\n",
    "                tweet_user_id = int(tweet_pq('a.js-user-profile-link').attr('data-user-id'))\n",
    "                geo_span = tweet_pq('span.Tweet-geo')\n",
    "                geo = geo_span.attr('title') if len(geo_span) > 0 else ''\n",
    "                urls = []\n",
    "                for link in tweet_pq('a'):\n",
    "                    try:\n",
    "                        urls.append((link.attrib['data-expanded-url']))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                tweet.tweet_id = tweet_id\n",
    "                tweet.permalink = f'https://twitter.com{permalink}'\n",
    "                tweet.username = tweet_username\n",
    "                tweet.text = tweet_text\n",
    "                tweet.date = datetime.datetime.fromtimestamp(date_info)\n",
    "                tweet.formatted_date = datetime.datetime.fromtimestamp(date_info).strftime('%a %b %d %X +0000 %Y')\n",
    "                tweet.retweets = retweets\n",
    "                tweet.favorites = favorites\n",
    "                tweet.mentions = ' '.join(re.compile(r'(@\\\\w*)').findall(tweet.text))\n",
    "                tweet.hashtags = ' '.join(re.compile(r'(#\\\\w*)').findall(tweet.text))\n",
    "                tweet.geo = geo\n",
    "                tweet.urls = ','.join(urls)\n",
    "                tweet.user_id = tweet_user_id\n",
    "                results.append(tweet)\n",
    "\n",
    "                if args.results > 0 and len(results) >= args.results:\n",
    "                    active = False\n",
    "                    break\n",
    "\n",
    "            if verbose:\n",
    "                print(f'collected {len(results)} tweets')\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_json_reponse(args, refresh_cursor, cookie_jar, proxy):\n",
    "        \"\"\"\n",
    "        Collects the twitter query response.\n",
    "        \"\"\"\n",
    "        url_get_data = ''\n",
    "        if args.username is not None:\n",
    "            url_get_data += f' from:{args.username}'\n",
    "        if args.since is not None:\n",
    "            url_get_data += f' since:{args.since}'\n",
    "        if args.until is not None:\n",
    "            url_get_data += f' until:{args.until}'\n",
    "        if args.location is not None:\n",
    "            url_get_data += f' near:{args.location}'\n",
    "            if args.location_radius is not None:\n",
    "                url_get_data += f' within:{args.location_radius}mi'\n",
    "        if args.query is not None:\n",
    "            url_get_data += f' {args.query}'\n",
    "        url_lang = f'lang={args.lang}&' if args.lang  is not None else ''\n",
    "\n",
    "        url = 'https://twitter.com/i/search/timeline?f=tweets&q=%s&src=typd&%smax_position=%s'\n",
    "        url = url % (urllib.parse.quote(url_get_data), url_lang, refresh_cursor)\n",
    "\n",
    "        headers = [\n",
    "            ('Host', 'twitter.com'),\n",
    "            ('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'),\n",
    "            ('Accept', 'application/json, text/javascript, */*; q=0.01'),\n",
    "            ('Accept-Language', 'de,en-US;q=0.7,en;q=0.3'),\n",
    "            ('X-Requested-With', 'XMLHttpRequest'),\n",
    "            ('Referer', url),\n",
    "            ('Connection', 'keep-alive')\n",
    "        ]\n",
    "\n",
    "        if proxy:\n",
    "            opener = urllib.request.build_opener(\n",
    "                urllib.request.ProxyHandler({'http': proxy, 'https': proxy}),\n",
    "                urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "        else:\n",
    "            opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "        opener.addheaders = headers\n",
    "\n",
    "        try:\n",
    "            response = opener.open(url)\n",
    "            jsonResponse = response.read()\n",
    "        except:\n",
    "            raise ConnectionError(f'Twitter weird response. Try to see on browser: https://twitter.com/search?q={urllib.parse.quote(url_get_data)}&src=typd')\n",
    "\n",
    "        dataJson = json.loads(jsonResponse.decode())\n",
    "        return dataJson\n",
    "\n",
    "\n",
    "def collect_event_tweets(query, since, until, results_per_day=1000, location=None, location_radius=None,\n",
    "                         on_some_collected=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Helps the tweet collect by getting they per day in a received time interval.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('collecting tweets of event per day')\n",
    "\n",
    "    tweets = []\n",
    "    current_date = datetime.date(*(int(i) for i in since.split('-')))\n",
    "    until_date = datetime.date(*(int(i) for i in until.split('-')))\n",
    "\n",
    "    while current_date != until_date:\n",
    "        next_date = current_date + relativedelta(days=1)\n",
    "        if verbose:\n",
    "            print(f'current day: {str(current_date)}')\n",
    "\n",
    "        args = QueryArgs(\n",
    "            query=query,\n",
    "            results=results_per_day,\n",
    "            location=location,\n",
    "            location_radius=location_radius,\n",
    "            since=str(current_date),\n",
    "            until=str(next_date))\n",
    "\n",
    "        try:\n",
    "            current_day_tweets = TweetAdvancedQuery().query(args, verbose=verbose)\n",
    "        except ConnectionError as e:\n",
    "            print(e)\n",
    "            print(f'error while collecting tweets of day {current_date}')\n",
    "            continue\n",
    "\n",
    "        tweets.extend(current_day_tweets)\n",
    "        if on_some_collected is not None:\n",
    "            on_some_collected(current_day_tweets)\n",
    "\n",
    "        current_date = next_date\n",
    "\n",
    "    return tweets\n",
    "\n",
    "tweets = []    \n",
    "collect_event_tweets(query=\"Worlds2017\", results_per_day=1000, since='2017-10-01', until='2017-11-04',on_some_collected = lambda dt: tweets.extend(dt),verbose=True)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweet_columns = ['date', 'tweet']\n",
    "\n",
    "tweets_data = [{'date':tweet.date, 'tweet':tweet.text} for tweet in tweets]\n",
    "    \n",
    "tweets_dataFrame = pd.DataFrame(tweets_data, columns=tweet_columns)\n",
    "tweets_dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
