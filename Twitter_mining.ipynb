{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import http.cookiejar\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyquery import PyQuery\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando classes e métodos de suporte a mineração no Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    \"\"\"\n",
    "    Holds tweet information.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class QueryArgs:\n",
    "    \"\"\"\n",
    "    Twitter advanced search arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, results=1, query=None, username=None, location=None, location_radius=None, since=None,\n",
    "                 until=None, lang=None, top_tweets=None):\n",
    "        self.results = results\n",
    "        self.query = query\n",
    "        self.username = username\n",
    "        self.location = location\n",
    "        self.location_radius = location_radius\n",
    "        self.since = since\n",
    "        self.until = until\n",
    "        self.lang = lang\n",
    "        self.top_tweets = top_tweets\n",
    "\n",
    "\n",
    "class TweetAdvancedQuery:\n",
    "    \"\"\"\n",
    "    Runs the search using http and json to recover the tweet information.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def query(args, proxy=None, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs the query with the received args and returns the collected tweets.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print('Start collect')\n",
    "\n",
    "        refresh_cursor = ''\n",
    "        results = []\n",
    "        cookie_jar = http.cookiejar.CookieJar()\n",
    "        active = True\n",
    "\n",
    "        while active:\n",
    "            json = TweetAdvancedQuery._get_json_reponse(args, refresh_cursor, cookie_jar, proxy)\n",
    "            if len(json['items_html'].strip()) == 0:\n",
    "                break\n",
    "\n",
    "            refresh_cursor = json['min_position']            \n",
    "            tweets = PyQuery(json['items_html'])('div.js-stream-tweet')\n",
    "            if len(tweets) == 0:\n",
    "                break\n",
    "\n",
    "            for tweet_html in tweets:\n",
    "                tweet_pq = PyQuery(tweet_html)\n",
    "                tweet = Tweet()\n",
    "                tweet_username = tweet_pq('span.username.js-action-profile-name b').text()\n",
    "                tweet_text = re.sub(r'\\s+', ' ', tweet_pq('p.js-tweet-text').text().replace('# ', '#').replace('@ ', '@'))\n",
    "                retweets = int(tweet_pq('span.ProfileTweet-action--retweet span.ProfileTweet-actionCount').attr('data-tweet-stat-count').replace(',', ''))\n",
    "                favorites = int(tweet_pq('span.ProfileTweet-action--favorite span.ProfileTweet-actionCount').attr('data-tweet-stat-count').replace(',', ''))\n",
    "                date_info = int(tweet_pq('small.time span.js-short-timestamp').attr('data-time'))\n",
    "                tweet_id = tweet_pq.attr('data-tweet-tweet_id')\n",
    "                permalink = tweet_pq.attr('data-permalink-path')\n",
    "                tweet_user_id = int(tweet_pq('a.js-user-profile-link').attr('data-user-id'))\n",
    "                geo_span = tweet_pq('span.Tweet-geo')\n",
    "                geo = geo_span.attr('title') if len(geo_span) > 0 else ''\n",
    "                urls = []\n",
    "                for link in tweet_pq('a'):\n",
    "                    try:\n",
    "                        urls.append((link.attrib['data-expanded-url']))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                tweet.tweet_id = tweet_id\n",
    "                tweet.permalink = f'https://twitter.com{permalink}'\n",
    "                tweet.username = tweet_username\n",
    "                tweet.text = tweet_text\n",
    "                tweet.date = datetime.datetime.fromtimestamp(date_info)\n",
    "                tweet.formatted_date = datetime.datetime.fromtimestamp(date_info).strftime('%a %b %d %X +0000 %Y')\n",
    "                tweet.retweets = retweets\n",
    "                tweet.favorites = favorites\n",
    "                tweet.mentions = ' '.join(re.compile(r'(@\\\\w*)').findall(tweet.text))\n",
    "                tweet.hashtags = ' '.join(re.compile(r'(#\\\\w*)').findall(tweet.text))\n",
    "                tweet.geo = geo\n",
    "                tweet.urls = ','.join(urls)\n",
    "                tweet.user_id = tweet_user_id\n",
    "                results.append(tweet)\n",
    "\n",
    "                if args.results > 0 and len(results) >= args.results:\n",
    "                    active = False\n",
    "                    break\n",
    "\n",
    "            if verbose:\n",
    "                print(f'collected {len(results)} tweets')\n",
    "\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_json_reponse(args, refresh_cursor, cookie_jar, proxy):\n",
    "        \"\"\"\n",
    "        Collects the twitter query response.\n",
    "        \"\"\"\n",
    "        url_get_data = ''\n",
    "        if args.username is not None:\n",
    "            url_get_data += f' from:{args.username}'\n",
    "        if args.since is not None:\n",
    "            url_get_data += f' since:{args.since}'\n",
    "        if args.until is not None:\n",
    "            url_get_data += f' until:{args.until}'\n",
    "        if args.location is not None:\n",
    "            url_get_data += f' near:{args.location}'\n",
    "            if args.location_radius is not None:\n",
    "                url_get_data += f' within:{args.location_radius}mi'\n",
    "        if args.query is not None:\n",
    "            url_get_data += f' {args.query}'\n",
    "        url_lang = f'lang={args.lang}&' if args.lang  is not None else ''\n",
    "\n",
    "        url = 'https://twitter.com/i/search/timeline?l=en&f=tweets&q=%s&src=typd&%smax_position=%s'\n",
    "        url = url % (urllib.parse.quote(url_get_data), url_lang, refresh_cursor)\n",
    "       \n",
    "        headers = [\n",
    "            ('Host', 'twitter.com'),\n",
    "            ('User-Agent', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'),\n",
    "            ('Accept', 'application/json, text/javascript, */*; q=0.01'),\n",
    "            ('Accept-Language', 'de,en-US;q=0.7,en;q=0.3'),\n",
    "            ('X-Requested-With', 'XMLHttpRequest'),\n",
    "            ('Referer', url),\n",
    "            ('Connection', 'keep-alive')\n",
    "        ]\n",
    "\n",
    "        if proxy:\n",
    "            opener = urllib.request.build_opener(\n",
    "                urllib.request.ProxyHandler({'http': proxy, 'https': proxy}),\n",
    "                urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "        else:\n",
    "            opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "        opener.addheaders = headers\n",
    "\n",
    "        try:\n",
    "            response = opener.open(url)\n",
    "            jsonResponse = response.read()\n",
    "        except:\n",
    "            raise ConnectionError(f'Twitter weird response. Try to see on browser: https://twitter.com/search?q={urllib.parse.quote(url_get_data)}&src=typd')\n",
    "\n",
    "        dataJson = json.loads(jsonResponse.decode())\n",
    "        return dataJson\n",
    "\n",
    "\n",
    "def collect_event_tweets(query, since, until, results_per_day=1000, location=None, location_radius=None,\n",
    "                         on_some_collected=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Helps the tweet collect by getting they per day in a received time interval.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('collecting tweets of event per day')\n",
    "\n",
    "    tweets = []\n",
    "    current_date = datetime.date(*(int(i) for i in since.split('-')))\n",
    "    until_date = datetime.date(*(int(i) for i in until.split('-')))\n",
    "\n",
    "    while current_date != until_date:\n",
    "        next_date = current_date + relativedelta(days=1)\n",
    "        if verbose:\n",
    "            print(f'current day: {str(current_date)}')\n",
    "\n",
    "        args = QueryArgs(\n",
    "            query=query,\n",
    "            lang=\"en\",\n",
    "            results=results_per_day,\n",
    "            location=location,\n",
    "            location_radius=location_radius,\n",
    "            since=str(current_date),\n",
    "            until=str(next_date))\n",
    "\n",
    "        try:\n",
    "            current_day_tweets = TweetAdvancedQuery().query(args, verbose=verbose)\n",
    "        except ConnectionError as e:\n",
    "            print(e)\n",
    "            print(f'error while collecting tweets of day {current_date}')\n",
    "            continue\n",
    "\n",
    "        tweets.extend(current_day_tweets)\n",
    "        if on_some_collected is not None:\n",
    "            on_some_collected(current_day_tweets)\n",
    "\n",
    "        current_date = next_date\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando tweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-19\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-20\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 78 tweets\n",
      "collected 96 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 36 tweets\n",
      "collected 56 tweets\n",
      "collected 76 tweets\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-21%20until%3A2017-10-22%20Worlds2017&src=typd\n",
      "error while collecting tweets of day 2017-10-21\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 36 tweets\n",
      "collected 56 tweets\n",
      "collected 76 tweets\n",
      "collected 94 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-22\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 79 tweets\n",
      "collected 97 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-23\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-24\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 58 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-25\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-26\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 78 tweets\n",
      "collected 96 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-27\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-28\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-29\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 77 tweets\n",
      "collected 97 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-30\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 76 tweets\n",
      "collected 96 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-31\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-01\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-02\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 93 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-03\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []    \n",
    "collect_event_tweets(query=\"Worlds2017\", results_per_day=100, since='2017-10-16', until='2017-11-04',on_some_collected = lambda dt: tweets.extend(dt),verbose=True)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando data frame com tweeters coletados e criando um CSV para armazernar os tweeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-16 20:53:27</td>\n",
       "      <td>I liked a @YouTube video http:// youtu.be/yCx3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-16 20:47:20</td>\n",
       "      <td>Fnatic's Miracle Run &amp; America's Last Hope - T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-16 20:46:40</td>\n",
       "      <td>Shanghai #worlds2017 semifinal tickets go on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-16 20:46:29</td>\n",
       "      <td>Me ha gustado un vídeo de @YouTube ( http:// y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-16 20:44:34</td>\n",
       "      <td>Discover Worlds with @TravisGafford and @Mobal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              tweet\n",
       "0 2017-10-16 20:53:27  I liked a @YouTube video http:// youtu.be/yCx3...\n",
       "1 2017-10-16 20:47:20  Fnatic's Miracle Run & America's Last Hope - T...\n",
       "2 2017-10-16 20:46:40  Shanghai #worlds2017 semifinal tickets go on s...\n",
       "3 2017-10-16 20:46:29  Me ha gustado un vídeo de @YouTube ( http:// y...\n",
       "4 2017-10-16 20:44:34  Discover Worlds with @TravisGafford and @Mobal..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_columns = ['date', 'tweet']\n",
    "\n",
    "tweets_data = [{'date':tweet.date, 'tweet':tweet.text} for tweet in tweets]\n",
    "    \n",
    "tweets_dataFrame = pd.DataFrame(tweets_data, columns=tweet_columns)\n",
    "tweets_dataFrame['tweet'] = tweets_dataFrame['tweet'].str.replace(';', ',')\n",
    "tweets_dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_dataFrame.to_csv(\"tweets\", sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez minerados os twitters gerais sobre o campeonato, seguiremos minerando as opiniões a cerca de cada time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "FNC\n",
      "0\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 77 tweets\n",
      "collected 94 tweets\n",
      "collected 100 tweets\n",
      "MSF\n",
      "1\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 16 tweets\n",
      "collected 36 tweets\n",
      "collected 52 tweets\n",
      "collected 71 tweets\n",
      "collected 91 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 17 tweets\n",
      "collected 35 tweets\n",
      "collected 55 tweets\n",
      "collected 75 tweets\n",
      "collected 95 tweets\n",
      "collected 100 tweets\n",
      "C9\n",
      "2\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 34 tweets\n",
      "collected 52 tweets\n",
      "collected 72 tweets\n",
      "collected 91 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 17 tweets\n",
      "collected 37 tweets\n",
      "collected 56 tweets\n",
      "collected 76 tweets\n",
      "collected 96 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 36 tweets\n",
      "collected 56 tweets\n",
      "collected 76 tweets\n",
      "collected 95 tweets\n",
      "collected 100 tweets\n",
      "LZ\n",
      "3\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "WE\n",
      "4\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 19 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-19\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-20\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 38 tweets\n",
      "collected 55 tweets\n",
      "collected 75 tweets\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-21%20until%3A2017-10-22%20WE&src=typd\n",
      "error while collecting tweets of day 2017-10-21\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 38 tweets\n",
      "collected 55 tweets\n",
      "collected 75 tweets\n",
      "collected 95 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-22\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-23\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-24\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-25\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-26\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-27\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 58 tweets\n",
      "collected 77 tweets\n",
      "collected 97 tweets\n",
      "collected 100 tweets\n",
      "RNG\n",
      "5\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-19\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-20\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-22\n",
      "Start collect\n",
      "collected 19 tweets\n",
      "collected 37 tweets\n",
      "collected 57 tweets\n",
      "collected 77 tweets\n",
      "collected 95 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-23\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-24\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-25\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-26\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-27\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "SKT\n",
      "6\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-19\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-20\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 58 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-22\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-23\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-24\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 58 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-25\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-26\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-27\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-28\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-29\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-30\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-31\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 100 tweets\n",
      "current day: 2017-11-01\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-02\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-03\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "SSG\n",
      "7\n",
      "collecting tweets of event per day\n",
      "current day: 2017-10-16\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 78 tweets\n",
      "collected 97 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-17\n",
      "Start collect\n",
      "collected 16 tweets\n",
      "collected 31 tweets\n",
      "collected 51 tweets\n",
      "collected 71 tweets\n",
      "collected 91 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-18\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 39 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 99 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-19\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 38 tweets\n",
      "collected 58 tweets\n",
      "collected 77 tweets\n",
      "collected 97 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-20\n",
      "Start collect\n",
      "collected 15 tweets\n",
      "collected 32 tweets\n",
      "collected 52 tweets\n",
      "collected 72 tweets\n",
      "collected 92 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-21\n",
      "Start collect\n",
      "collected 15 tweets\n",
      "collected 34 tweets\n",
      "collected 54 tweets\n",
      "collected 73 tweets\n",
      "collected 90 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-22\n",
      "Start collect\n",
      "collected 17 tweets\n",
      "collected 33 tweets\n",
      "collected 53 tweets\n",
      "collected 73 tweets\n",
      "collected 90 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-23\n",
      "Start collect\n",
      "collected 19 tweets\n",
      "collected 38 tweets\n",
      "collected 54 tweets\n",
      "collected 74 tweets\n",
      "collected 91 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-24\n",
      "Start collect\n",
      "collected 19 tweets\n",
      "collected 36 tweets\n",
      "collected 53 tweets\n",
      "collected 73 tweets\n",
      "collected 93 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-25\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 38 tweets\n",
      "collected 57 tweets\n",
      "collected 77 tweets\n",
      "collected 96 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-26\n",
      "Start collect\n",
      "collected 17 tweets\n",
      "collected 36 tweets\n",
      "collected 56 tweets\n",
      "collected 72 tweets\n",
      "collected 91 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-27\n",
      "Start collect\n",
      "collected 18 tweets\n",
      "collected 35 tweets\n",
      "collected 52 tweets\n",
      "collected 72 tweets\n",
      "collected 92 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-28\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-29\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 35 tweets\n",
      "collected 55 tweets\n",
      "collected 73 tweets\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20since%3A2017-10-29%20until%3A2017-10-30%20SSG&src=typd\n",
      "error while collecting tweets of day 2017-10-29\n",
      "current day: 2017-10-29\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 35 tweets\n",
      "collected 55 tweets\n",
      "collected 73 tweets\n",
      "collected 93 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-30\n",
      "Start collect\n",
      "collected 19 tweets\n",
      "collected 34 tweets\n",
      "collected 54 tweets\n",
      "collected 74 tweets\n",
      "collected 94 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-10-31\n",
      "Start collect\n",
      "collected 17 tweets\n",
      "collected 34 tweets\n",
      "collected 52 tweets\n",
      "collected 72 tweets\n",
      "collected 92 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-01\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 59 tweets\n",
      "collected 79 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-02\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 58 tweets\n",
      "collected 78 tweets\n",
      "collected 98 tweets\n",
      "collected 100 tweets\n",
      "current day: 2017-11-03\n",
      "Start collect\n",
      "collected 20 tweets\n",
      "collected 40 tweets\n",
      "collected 60 tweets\n",
      "collected 80 tweets\n",
      "collected 100 tweets\n"
     ]
    }
   ],
   "source": [
    "teams = ['FNC', 'MSF', 'C9', 'LZ','WE', 'RNG', 'SKT', 'SSG']\n",
    "#since='2017-10-16'\n",
    "#until='2017-11-04'\n",
    "#final dates https://www.maisesports.com.br/mundial-2017-cobertura-tabelas-datas/\n",
    "key_dates = ['2017-10-19','2017-10-28','2017-11-04']\n",
    "tweet_columns = ['date', 'tweet']\n",
    "teamns_tweets = []\n",
    "print('finished')\n",
    "\n",
    "for index, team in enumerate(teams):\n",
    "    print(team)\n",
    "    key_index = 2;\n",
    "    print(index)\n",
    "    if index < 4:\n",
    "        key_index = 0\n",
    "    elif index < 6:\n",
    "        key_index = 1\n",
    "    collect_event_tweets(query=team, results_per_day=100, since='2017-10-16', until=key_dates[key_index],on_some_collected = lambda dt: teamns_tweets.extend(dt),verbose=True)\n",
    "\n",
    "    tweets_data = [{'date':tweet.date, 'tweet':tweet.text, 'team':team} for tweet in teamns_tweets]\n",
    "\n",
    "    tweets_dataFrame = pd.DataFrame(tweets_data, columns=tweet_columns)\n",
    "    tweets_dataFrame['tweet'] = tweets_dataFrame['tweet'].str.replace(';', ',')\n",
    "    tweets_dataFrame.head()\n",
    "\n",
    "    tweets_dataFrame.to_csv(team, sep=';', encoding='utf-8')\n",
    "    \n",
    "    teamns_tweets = []\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
